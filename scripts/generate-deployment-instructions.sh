#!/bin/bash

# Deployment Instructions Generator
# Generates customized deployment instructions based on the environment configuration

set -e

# Color codes for output
GREEN=$'\033[0;32m'
YELLOW=$'\033[1;33m'
CYAN=$'\033[0;36m'
NC=$'\033[0m' # No Color

generate_instructions() {
    local env_url=$1

    cat <<EOF

${GREEN}════════════════════════════════════════════════════════════════════════${NC}
${GREEN}  AWS Elastic Beanstalk Environment Setup Complete!${NC}
${GREEN}════════════════════════════════════════════════════════════════════════${NC}

${CYAN}Environment Details:${NC}
  Application Name:    $APP_NAME
  Environment Name:    $ENV_NAME
  Region:              $AWS_REGION
  Environment URL:     http://$env_url
  HTTPS URL:           https://$env_url

${CYAN}S3 Buckets Created:${NC}
  Static Assets:       $STATIC_ASSETS_BUCKET
  File Uploads:        $UPLOADS_BUCKET

${CYAN}Environment Variables (already configured):${NC}
  STATIC_ASSETS_BUCKET=$STATIC_ASSETS_BUCKET
  UPLOADS_BUCKET=$UPLOADS_BUCKET
  AWS_REGION=$AWS_REGION

EOF

  # Check if database was configured
  if [ -n "${DB_NAME:-}" ] && [ -f /tmp/db-env-options.json ]; then
    cat <<EOF
${CYAN}Database Environment Variables (automatically configured):${NC}
  DATABASE_URL=<auto-generated-connection-string>
  DB_HOST=<rds-endpoint>
  DB_PORT=<db-port>
  DB_NAME=$DB_NAME
  DB_USERNAME=$DB_USERNAME
  DB_PASSWORD=<secure-password-stored-in-secrets-manager>

EOF
  fi

  cat <<EOF
${GREEN}  Next Steps: Deploying Your Application${NC}
${GREEN}────────────────────────────────────────────────────────────────────────${NC}

${YELLOW}Step 1: Initialize EB CLI in your application directory${NC}

  cd /path/to/your/application
  eb init --profile $AWS_PROFILE --region $AWS_REGION

  When prompted:
  - Select application: $APP_NAME
  - Select environment: $ENV_NAME

${YELLOW}Step 2: Deploy your application${NC}

  eb deploy $ENV_NAME --profile $AWS_PROFILE

${YELLOW}Step 3: Access S3 buckets and database from your application${NC}

  The following environment variables are available in your application:

  - STATIC_ASSETS_BUCKET: Use for serving static files (CSS, JS, images)
  - UPLOADS_BUCKET: Use for user file uploads
  - AWS_REGION: AWS region where resources are located

EOF

  # Add database variables if configured
  if [ -n "${DB_NAME:-}" ] && [ -f /tmp/db-env-options.json ]; then
    cat <<EOF
  Database connection variables (if RDS database was configured):
  - DATABASE_URL: Complete connection string for database access
  - DB_HOST: Database endpoint hostname
  - DB_PORT: Database port number
  - DB_NAME: Database name
  - DB_USERNAME: Database username
  - DB_PASSWORD: Database password (stored securely)

EOF
  fi

  cat <<EOF

  Example Python code using boto3:

    import os
    import boto3

    s3 = boto3.client("s3", region_name=os.environ["AWS_REGION"])
    
    # Upload a file
    s3.upload_file(
        "local_file.jpg",
        os.environ["UPLOADS_BUCKET"],
        "uploads/file.jpg"
    )
    
    # Get file URL
    url = s3.generate_presigned_url(
        "get_object",
        Params={
            "Bucket": os.environ["STATIC_ASSETS_BUCKET"],
            "Key": "static/image.jpg"
        },
        ExpiresIn=3600
    )

EOF

  # Add database examples if configured
  if [ -n "${DB_NAME:-}" ] && [ -f /tmp/db-env-options.json ]; then
    cat <<EOF
  Example Python database connection using psycopg2:

    import os
    import psycopg2

    # Using DATABASE_URL (recommended)
    conn = psycopg2.connect(os.environ["DATABASE_URL"])

    # Or using individual variables
    conn = psycopg2.connect(
        host=os.environ["DB_HOST"],
        port=os.environ["DB_PORT"],
        database=os.environ["DB_NAME"],
        user=os.environ["DB_USERNAME"],
        password=os.environ["DB_PASSWORD"]
    )

    # Example query
    with conn.cursor() as cursor:
        cursor.execute("SELECT version()")
        result = cursor.fetchone()
        print(f"Database version: {result[0]}")

    conn.close()

  Example Node.js database connection using pg:

    const { Client } = require('pg');

    // Using DATABASE_URL (recommended)
    const client = new Client({
      connectionString: process.env.DATABASE_URL,
    });

    // Or using individual variables
    const client = new Client({
      host: process.env.DB_HOST,
      port: process.env.DB_PORT,
      database: process.env.DB_NAME,
      user: process.env.DB_USERNAME,
      password: process.env.DB_PASSWORD,
    });

    await client.connect();
    const res = await client.query('SELECT version()');
    console.log('Database version:', res.rows[0]);
    await client.end();

EOF
  fi

  cat <<EOF

${YELLOW}Step 4: Configure your custom domain (optional)${NC}

EOF

    # Check if custom domain was configured
    if [ -f /tmp/custom-domain.txt ]; then
        local custom_domain=$(cat /tmp/custom-domain.txt)
        cat <<EOF
  ${GREEN}✓ Custom domain configured: $custom_domain${NC}

  Your application should be accessible at:
    https://$custom_domain (after DNS propagates)

  To verify DNS configuration:
    dig $custom_domain +short
    # or
    nslookup $custom_domain

EOF
    else
        cat <<EOF
  To use a custom domain with this environment:

  ${CYAN}Option 1: Manual DNS Configuration${NC}
  1. Create a CNAME record in your DNS provider:
     
     For subdomain (api.example.com, www.example.com):
       Record Type: CNAME
       Name:        subdomain (e.g., api, www)
       Target:      $env_url
       TTL:         300

     For root domain (example.com):
       Record Type: ALIAS (or A with IP lookup)
       Name:        @ (or leave blank)
       Target:      $env_url
       TTL:         300

  2. Wait for DNS propagation (usually 5-30 minutes, can take up to 48 hours)

  ${CYAN}Option 2: Automatic Route 53 Configuration${NC}
  1. Update config.env:
       CUSTOM_DOMAIN="your-domain.com"
       AUTO_CONFIGURE_DNS="true"

  2. Re-run the setup script:
       ./setup-eb-environment.sh

  The script will automatically create DNS records in Route 53 (if hosted there)

EOF
    fi

    cat <<EOF
${YELLOW}Step 5: Manage additional domains or subdomains${NC}

  You can add multiple domains/subdomains pointing to this environment:

  ${CYAN}Using the Route 53 DNS management script:${NC}
    
    # List your hosted zones
    ./scripts/setup-route53-dns.sh list-zones
    
    # Create a CNAME record for a subdomain
    ./scripts/setup-route53-dns.sh create-cname ZONE_ID api.example.com $env_url
    
    # Create an ALIAS record for root domain (requires load balancer zone ID)
    # ./scripts/setup-route53-dns.sh create-alias ZONE_ID example.com $env_url LB_ZONE_ID
    
    # View all commands
    ./scripts/setup-route53-dns.sh help

${YELLOW}Step 6: Monitor your environment${NC}

  # View environment status
  eb status $ENV_NAME --profile $AWS_PROFILE

  # View logs
  eb logs $ENV_NAME --profile $AWS_PROFILE

  # Open environment in browser
  eb open $ENV_NAME --profile $AWS_PROFILE

  # SSH into instance (if key pair configured)
  eb ssh $ENV_NAME --profile $AWS_PROFILE

${GREEN}────────────────────────────────────────────────────────────────────────${NC}
${GREEN}  Useful EB CLI Commands${NC}
${GREEN}────────────────────────────────────────────────────────────────────────${NC}

  eb deploy              Deploy your application
  eb status              Check environment status
  eb health              View environment health
  eb logs                Retrieve environment logs
  eb config              View/edit configuration
  eb setenv KEY=VALUE    Set environment variables
  eb printenv            Print environment variables
  eb terminate           Terminate the environment

${GREEN}────────────────────────────────────────────────────────────────────────${NC}
${GREEN}  Managing S3 Buckets${NC}
${GREEN}────────────────────────────────────────────────────────────────────────${NC}

  # List files in static assets bucket
  aws s3 ls s3://$STATIC_ASSETS_BUCKET/ --profile $AWS_PROFILE

  # Upload files to static assets bucket
  aws s3 cp local-file.jpg s3://$STATIC_ASSETS_BUCKET/images/ --profile $AWS_PROFILE

  # Sync directory to static assets bucket
  aws s3 sync ./static/ s3://$STATIC_ASSETS_BUCKET/static/ --profile $AWS_PROFILE

  # List uploads
  aws s3 ls s3://$UPLOADS_BUCKET/ --profile $AWS_PROFILE

${GREEN}────────────────────────────────────────────────────────────────────────${NC}
${GREEN}  Troubleshooting${NC}
${GREEN}────────────────────────────────────────────────────────────────────────${NC}

  If deployment fails:
  
  1. Check environment health:
     eb health $ENV_NAME --profile $AWS_PROFILE --refresh

  2. View recent logs:
     eb logs $ENV_NAME --profile $AWS_PROFILE

  3. Check environment events:
     aws elasticbeanstalk describe-events \\
       --environment-name $ENV_NAME \\
       --profile $AWS_PROFILE \\
       --region $AWS_REGION \\
       --max-items 20

  If HTTPS is not working:
  
  1. Verify certificate status:
     aws acm describe-certificate \\
       --certificate-arn \$(cat /tmp/acm-cert-arn.txt 2>/dev/null || echo "YOUR_CERT_ARN") \\
       --profile $AWS_PROFILE \\
       --region $AWS_REGION

  2. Wait a few minutes for SSL configuration to propagate

${GREEN}════════════════════════════════════════════════════════════════════════${NC}

EOF
}

main() {
    # Read environment URL
    local env_url
    if [ -f /tmp/eb-env-url.txt ]; then
        env_url=$(cat /tmp/eb-env-url.txt)
    else
        env_url="<environment-url>"
    fi

    generate_instructions "$env_url"
}

# Run main function if script is executed directly
if [ "${BASH_SOURCE[0]}" = "${0}" ]; then
    main "$@"
fi

